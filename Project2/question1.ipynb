{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "y_train = np.load(\"orientations_train.npy\")\n",
    "y_test = np.load(\"orientations_test.npy\")\n",
    "\n",
    "test_size = 1000\n",
    "train_size = 10000\n",
    "image_length = 4096\n",
    "image_dim = 64\n",
    "\n",
    "def vectorize_images(filename, data_size):\n",
    "    X = np.empty(shape=(data_size, image_length))\n",
    "   \n",
    "    for i in range(data_size):     \n",
    "        img = cv.imread(\"{filename}/{i}.jpg\".format(filename = filename, i = i), cv.IMREAD_GRAYSCALE)\n",
    "        X[i] = img.flatten()\n",
    "        \n",
    "    return X\n",
    "\n",
    "X_train = vectorize_images(\"3dshapes_train\" ,train_size)\n",
    "X_test = vectorize_images(\"3dshapes_test\" ,test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_svm(X_train, X_test, y_train, kernel, C=1.0, gamma='scale',coef0=0.0, degree=3):\n",
    "    # Train SVM classifier\n",
    "    # C: regularization parameter of the SVM\n",
    "         # A small value of C will result in a wider margin hyperplane and a larger number of support vectors. \n",
    "         # A large value of C will result in a a narrow margin hyperplane and smaller number of support vectors.\n",
    "    # random_state : random seed\n",
    "    clf = SVC(kernel=kernel, C=C, random_state=100,gamma=gamma)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    # Predict labels for validation set\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    return y_pred_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__ i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification accuracy: 1.0  for kernel: linear C: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Select two orientations for binary classification\n",
    "train_orients_set = list(set(y_train))\n",
    "orient1 = train_orients_set[0]   # 0\n",
    "orient2 = train_orients_set[1]   # 1\n",
    "\n",
    "# Create binary label vectors\n",
    "y_train_bin = np.empty(train_size)\n",
    "y_test_bin = np.empty(test_size)\n",
    "\n",
    "y_train_bin = np.delete(y_train, np.argwhere( (y_train != orient1) & (y_train != orient2) ))\n",
    "y_train_bin[y_train_bin == orient1] = 0\n",
    "y_train_bin[y_train_bin == orient2] = 1\n",
    "X_train_bin = X_train[(y_train == orient1) | (y_train == orient2)]\n",
    "\n",
    "y_test_bin = np.delete(y_test, np.argwhere( (y_test != orient1) & (y_test != orient2) ))\n",
    "y_test_bin[y_test_bin == orient1] = 0\n",
    "y_test_bin[y_test_bin == orient2] = 1\n",
    "X_test_bin = X_test[(y_test == orient1) | (y_test == orient2)]\n",
    "\n",
    "# Compute accuracy with best kernal and c(regularization parameter)\n",
    "C_grid = {'C': [0.1, 1, 10, 100, 1000]}\n",
    "kernel_grid = {'kernel':['linear','poly','rbf','sigmoid']}\n",
    "svm = SVC()\n",
    "grid_search = GridSearchCV(svm, kernel_grid, cv=4)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "best_kernel = grid_search.best_params_['kernel']\n",
    "\n",
    "svm = SVC(kernel = best_kernel)\n",
    "grid_search = GridSearchCV(svm, C_grid, cv=5)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "c = grid_search.best_params_['C']\n",
    "\n",
    "if best_kernel=='poly':\n",
    "    poly_grid = {'degree':[2,3,4,5], 'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, poly_grid, cv=4)\n",
    "    grid_search.fit(X_train_bin, y_train_bin)\n",
    "    \n",
    "elif best_kernel=='rbf':\n",
    "    rbf_grid = {'gamma':[1,0.1,0.01,0.001]}\n",
    "    grid_search = GridSearchCV(svm, rbf_grid, cv=4)\n",
    "    grid_search.fit(X_train_bin, y_train_bin)\n",
    "    \n",
    "elif best_kernel=='sigmoid':\n",
    "    sigmoid_grid = {'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, sigmoid_grid, cv=4)\n",
    "    grid_search.fit(X_train_bin, y_train_bin)\n",
    "    \n",
    "degree = grid_search.best_params_.get('degree',3)\n",
    "coefficient = grid_search.best_params_.get('coef0',0.0)\n",
    "gamma = grid_search.best_params_.get('gamma','scale')\n",
    "\n",
    "y_pred_bin = apply_svm(X_train_bin, X_test_bin, y_train_bin, best_kernel, C=c, coef0=coefficient, degree=degree)\n",
    "acc_bin_test = accuracy_score(y_test_bin, y_pred_bin)\n",
    "\n",
    "print(\"Binary classification accuracy:\",acc_bin_test,\" for kernel:\",best_kernel,\"C:\",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__ ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 class classification accuracy: 1.0  for kernel: linear C: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to integers from 1 to 15\n",
    "for i in range(len(train_orients_set)):\n",
    "    y_train[y_train == train_orients_set[i]] = i+1\n",
    "        \n",
    "test_orients_set = list(set(y_test))\n",
    "for i in range(len(test_orients_set)):\n",
    "    y_test[y_test == test_orients_set[i]] = i+1\n",
    "        \n",
    "# Compute validation accuracy\n",
    "y_pred = apply_svm(X_train, X_test, y_train, best_kernel, c)\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "print(\"15 class classification accuracy:\",acc_test,\" for kernel:\",best_kernel,\"C:\",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__ iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: linear C: 0.1\n",
      "Binary classification accuracy = 1.0 Precision = 1.0 Recall = 1.0 F1-Score = 1.0\n",
      "15 class classification accuracy = 1.0 Precision = 1.0 Recall = 1.0 F1-Score = 1.0\n"
     ]
    }
   ],
   "source": [
    "precision_bin = precision_score(y_test_bin, y_pred_bin, average='macro')\n",
    "recall_bin = recall_score(y_test_bin, y_pred_bin, average='macro')\n",
    "f1score_bin = f1_score(y_test_bin, y_pred_bin, average='macro')\n",
    "#cm_bin = confusion_matrix(y_test_bin, y_pred_bin)\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1score = f1_score(y_test, y_pred, average='macro')\n",
    "#cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'kernel: {best_kernel} C: {c}')\n",
    "print(f'Binary classification accuracy = {acc_bin_test} Precision = {precision_bin} Recall = {recall_bin} F1-Score = {f1score_bin}')\n",
    "print(f'15 class classification accuracy = {acc_test} Precision = {precision} Recall = {recall} F1-Score = {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b)__ Grid search is used to tune the hyperparameters such as C, degree, gamma, coefficient(coef0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard-margin linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard margin linear SVM C = 1e+21 kernel = linear\n",
      "Binary classification accuracy : 1.0\n",
      "15 class classification accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "# hard-margin linear SVM\n",
    "C_hard = 10e20\n",
    "y_pred_bin_hm_lin = apply_svm(X_train_bin, X_test_bin, y_train_bin, 'linear', C_hard)\n",
    "acc_bin_hm_lin = accuracy_score(y_test_bin, y_pred_bin_hm_lin)\n",
    "y_pred_hm_lin = apply_svm(X_train, X_test, y_train, 'linear', C_hard)\n",
    "acc_hm_lin = accuracy_score(y_test, y_pred_hm_lin)\n",
    "\n",
    "print(f'Hard margin linear SVM C = {C_hard} kernel = linear')\n",
    "print(\"Binary classification accuracy :\",acc_bin_hm_lin)\n",
    "print(\"15 class classification accuracy :\",acc_hm_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soft-margin linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft margin linear SVM C = 0.1 kernel = linear\n",
      "Binary classification accuracy : 1.0\n",
      "15 class classification accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "# soft-margin linear SVM\n",
    "# nonzero C value (e.g., 1, 10, or 100)\n",
    "C_grid = {'C': [0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# Perform a grid search with 5-fold cross-validation to find the best value of C\n",
    "svm = SVC(kernel='linear')\n",
    "grid_search = GridSearchCV(svm, C_grid, cv=5)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "C_hm_lin = grid_search.best_params_['C']\n",
    "\n",
    "y_pred_bin_sm_lin = apply_svm(X_train_bin, X_test_bin, y_train_bin, 'linear')\n",
    "acc_bin_sm_lin = accuracy_score(y_test_bin, y_pred_bin_sm_lin)\n",
    "y_pred_sm_lin = apply_svm(X_train, X_test, y_train, 'linear')\n",
    "acc_sm_lin = accuracy_score(y_test, y_pred_sm_lin)\n",
    "\n",
    "print(f'Soft margin linear SVM C = {C_hm_lin} kernel = linear')\n",
    "print(\"Binary classification accuracy :\",acc_bin_sm_lin)\n",
    "print(\"15 class classification accuracy :\",acc_sm_lin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard-margin non-linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard margin non linear SVM C = 1e+21 kernel = poly\n",
      "Binary classification accuracy : 1.0\n",
      "15 class classification accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "# hard-margin non-linear SVM with various kernel functions\n",
    "kernel_grid = {'kernel': ['poly','rbf', 'sigmoid']}\n",
    "# Perform a grid search with 3-fold cross-validation to find the best kernel function\n",
    "svm = SVC(C=C_hard)\n",
    "grid_search = GridSearchCV(svm, kernel_grid, cv=3)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "kernel_hm_nonlin = grid_search.best_params_['kernel']\n",
    "\n",
    "svm = SVC(kernel=kernel_hm_nonlin, C=C_hard)\n",
    "\n",
    "if kernel_hm_nonlin=='poly':\n",
    "    poly_grid = {'degree':[2,3,4,5], 'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, poly_grid, cv=4)\n",
    "    \n",
    "elif kernel_hm_nonlin=='rbf':\n",
    "    rbf_grid = {'gamma':[1,0.1,0.01,0.001]}\n",
    "    grid_search = GridSearchCV(svm, rbf_grid, cv=4)\n",
    "    \n",
    "elif kernel_hm_nonlin=='sigmoid':\n",
    "    sigmoid_grid = {'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, sigmoid_grid, cv=4)\n",
    "\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "degree = grid_search.best_params_.get('degree',3)\n",
    "coefficient = grid_search.best_params_.get('coef0',0.0)\n",
    "gamma = grid_search.best_params_.get('gamma','scale')\n",
    "\n",
    "y_pred_bin_hm_nonlin = apply_svm(X_train_bin, X_test_bin, y_train_bin, kernel_hm_nonlin, C=C_hard,coef0=coefficient,degree=degree)\n",
    "acc_bin_hm_nonlin = accuracy_score(y_test_bin, y_pred_bin_hm_nonlin)\n",
    "y_pred_hm_nonlin = apply_svm(X_train, X_test, y_train, kernel_hm_nonlin, C=C_hard)\n",
    "acc_hm_nonlin = accuracy_score(y_test, y_pred_hm_nonlin)\n",
    "\n",
    "print(f'Hard margin non linear SVM C = {C_hard} kernel = {kernel_hm_nonlin}')\n",
    "print(\"Binary classification accuracy :\",acc_bin_hm_nonlin)\n",
    "print(\"15 class classification accuracy :\",acc_hm_nonlin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soft-margin non-linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft margin non linear SVM C = 0.1 kernel = poly\n",
      "Binary classification accuracy : 1.0\n",
      "15 class classification accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "# soft-margin non-linear SVM with various kernel functions\n",
    "svm = SVC()\n",
    "grid_search = GridSearchCV(svm, kernel_grid, cv=3)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "kernel_sm_nonlin = grid_search.best_params_['kernel']\n",
    "\n",
    "svm = SVC(kernel = kernel_sm_nonlin)\n",
    "grid_search = GridSearchCV(svm, C_grid, cv=5)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "C_sm_nonlin = grid_search.best_params_['C']\n",
    "\n",
    "if kernel_hm_nonlin=='poly':\n",
    "    poly_grid = {'degree':[2,3,4,5], 'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, poly_grid, cv=4)\n",
    "    \n",
    "elif kernel_hm_nonlin=='rbf':\n",
    "    rbf_grid = {'gamma':[1,0.1,0.01,0.001]}\n",
    "    grid_search = GridSearchCV(svm, rbf_grid, cv=4)\n",
    "    \n",
    "elif kernel_hm_nonlin=='sigmoid':\n",
    "    sigmoid_grid = {'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, sigmoid_grid, cv=4)\n",
    "\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "degree = grid_search.best_params_.get('degree',3)\n",
    "coefficient = grid_search.best_params_.get('coef0',0.0)\n",
    "gamma = grid_search.best_params_.get('gamma','scale')\n",
    "\n",
    "y_pred_bin_sm_nonlin = apply_svm(X_train_bin, X_test_bin, y_train_bin, kernel_sm_nonlin, C=C_sm_nonlin,coef0=coefficient,degree=degree)\n",
    "acc_bin_sm_nonlin = accuracy_score(y_test_bin, y_pred_bin_sm_nonlin)\n",
    "y_pred_sm_nonlin = apply_svm(X_train, X_test, y_train, kernel_sm_nonlin, C=C_sm_nonlin)\n",
    "acc_sm_nonlin = accuracy_score(y_test, y_pred_sm_nonlin)\n",
    "\n",
    "print(f'Soft margin non linear SVM C = {C_sm_nonlin} kernel = {kernel_sm_nonlin}')\n",
    "print(\"Binary classification accuracy :\",acc_bin_sm_nonlin)\n",
    "print(\"15 class classification accuracy :\",acc_sm_nonlin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_svm_with_pca(X_train,X_test, y_train, kernel='rfb', C=1.0, gamma='scale'):\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled_train = scaler.fit_transform(X_train)\n",
    "    X_scaled_test = scaler.transform(X_test)\n",
    "\n",
    "    # Apply PCA to extract principal components\n",
    "    pca = PCA(n_components=10)     # n_components can be changed to extract more or fewer principal components as needed.\n",
    "    X_train_pca = pca.fit_transform(X_scaled_train)\n",
    "    X_test_pca = pca.transform(X_scaled_test)\n",
    "    \n",
    "    clf = SVC(kernel=kernel, C=C, random_state=100,gamma=gamma)\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Predict labels for validation set\n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification accuracy before pca: 1.0\n",
      "Binary classification accuracy after pca: 1.0\n",
      "15 class classification accuracy before pca: 1.0\n",
      "15 class classification accuracy after pca: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Compute validation accuracy for binary classification with pca\n",
    "y_pred_bin_pca = apply_svm_with_pca(X_train_bin, X_test_bin, y_train_bin, best_kernel, c)\n",
    "acc_bin_test_pca = accuracy_score(y_test_bin, y_pred_bin_pca)\n",
    "\n",
    "# Compute validation accuracy for 15 class classification with pca\n",
    "y_pred_pca = apply_svm_with_pca(X_train, X_test, y_train, best_kernel, c)\n",
    "acc_test_pca = accuracy_score(y_test, y_pred_pca)\n",
    "    \n",
    "print(\"Binary classification accuracy before pca:\", acc_bin_test)\n",
    "print(\"Binary classification accuracy after pca:\", acc_bin_test_pca)\n",
    "print(\"15 class classification accuracy before pca:\",acc_test)\n",
    "print(\"15 class classification accuracy after pca:\",acc_test_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
