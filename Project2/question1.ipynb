{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(a)__ In this question, we used sklearn library to extract features and use SVM classifier. In short, we transformed input data in a way that we can easily manipulate. (grayscale, flatten etc.) We named our classes 0,1....14 for the 15-class case. For the binary case, 0 and 1 classes are used. Also, we implemented an *apply_svm* function in order to train our data with the SVM classifier. <br> Kernel function can be either linear, polynomial, RBF and sigmoid. Therefore, it is given as a parameter in our function. <br> C is the regularization parameter. <br> Gamma parameter is given for the RBF function; however, we never actually used it. <br> Degree is the degree of the polynomial kernel. <br> After SVM is applied, we predict the labels for the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skimage.feature import hog\n",
    "\n",
    "y_train = np.load(\"orientations_train.npy\")\n",
    "y_test = np.load(\"orientations_test.npy\")\n",
    "\n",
    "test_size = 1000\n",
    "train_size = 10000\n",
    "image_length = 1764\n",
    "image_dim = 64\n",
    "\n",
    "def vectorize_images(filename, data_size):\n",
    "    X = np.empty(shape=(data_size, image_length))\n",
    "   \n",
    "    for i in range(data_size):     \n",
    "        img = cv.imread(\"{filename}/{i}.jpg\".format(filename = filename, i = i), cv.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        img_reshaped = img.reshape((image_dim, image_dim))\n",
    "\n",
    "        # Perform HOG feature extraction for the image\n",
    "        hog_img = hog(img_reshaped, orientations=9, pixels_per_cell=(8, 8),\n",
    "                      cells_per_block=(2, 2), visualize=False)\n",
    "                      \n",
    "        # orientations : Number of gradient orientations\n",
    "        # pixels_per_cell : Size of each cell\n",
    "        # cells_per_block : Number of cells in each block\n",
    "        \n",
    "        X[i] = hog_img.flatten()\n",
    "        \n",
    "        \n",
    "    return X\n",
    "\n",
    "X_train = vectorize_images(\"3dshapes_train\" ,train_size)\n",
    "X_test = vectorize_images(\"3dshapes_test\" ,test_size)\n",
    "\n",
    "# Convert labels to integers from 0 to 14\n",
    "train_orients_set = list(set(y_train))\n",
    "for i in range(len(train_orients_set)):\n",
    "    y_train[y_train == train_orients_set[i]] = i\n",
    "        \n",
    "test_orients_set = list(set(y_test))\n",
    "for i in range(len(test_orients_set)):\n",
    "    y_test[y_test == test_orients_set[i]] = i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_svm(X_train, X_test, y_train, kernel, C=1.0, gamma='scale',coef0=0.0, degree=3):\n",
    "    # Train SVM classifier\n",
    "    # C: regularization parameter of the SVM\n",
    "         # A small value of C will result in a wider margin hyperplane and a larger number of support vectors. \n",
    "         # A large value of C will result in a a narrow margin hyperplane and smaller number of support vectors.\n",
    "    clf = SVC(kernel=kernel, C=C, gamma=gamma)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    # Predict labels for validation set\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    return y_pred_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__ i) Below, we trained an SVM classifier for a binary classification. 0 and 1 are chosen for the binary classification.\n",
    "\n",
    "Grid Search was used to determine best kernel function and best value of regularization parameter (C) of SVM. Then, we trained the SVM classifier for the binary classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification accuracy: 1.0  for kernel: linear C: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Select two orientations for binary classification\n",
    "# Create binary label vectors\n",
    "y_train_bin = np.empty(train_size)\n",
    "y_test_bin = np.empty(test_size)\n",
    "\n",
    "y_train_bin = np.delete(y_train, np.argwhere( (y_train != 0) & (y_train != 1) ))\n",
    "X_train_bin = X_train[(y_train == 0) | (y_train == 1)]\n",
    "\n",
    "y_test_bin = np.delete(y_test, np.argwhere( (y_test != 0) & (y_test != 1) ))\n",
    "X_test_bin = X_test[(y_test == 0) | (y_test == 1)]\n",
    "\n",
    "# Compute accuracy with best kernal and c(regularization parameter)\n",
    "C_grid = {'C': [0.1, 1, 10, 100, 1000]}\n",
    "kernel_grid = {'kernel':['linear','poly','rbf','sigmoid']}\n",
    "svm = SVC()\n",
    "grid_search = GridSearchCV(svm, kernel_grid, cv=4)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "best_kernel = grid_search.best_params_['kernel']\n",
    "\n",
    "svm = SVC(kernel = best_kernel)\n",
    "grid_search = GridSearchCV(svm, C_grid, cv=5)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "c = grid_search.best_params_['C']\n",
    "\n",
    "if best_kernel=='poly':\n",
    "    poly_grid = {'degree':[2,3,4,5], 'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, poly_grid, cv=4)\n",
    "    grid_search.fit(X_train_bin, y_train_bin)\n",
    "    \n",
    "elif best_kernel=='rbf':\n",
    "    rbf_grid = {'gamma':[1,0.1,0.01,0.001]}\n",
    "    grid_search = GridSearchCV(svm, rbf_grid, cv=4)\n",
    "    grid_search.fit(X_train_bin, y_train_bin)\n",
    "    \n",
    "elif best_kernel=='sigmoid':\n",
    "    sigmoid_grid = {'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, sigmoid_grid, cv=4)\n",
    "    grid_search.fit(X_train_bin, y_train_bin)\n",
    "    \n",
    "degree = grid_search.best_params_.get('degree',3)\n",
    "coefficient = grid_search.best_params_.get('coef0',0.0)\n",
    "gamma = grid_search.best_params_.get('gamma','scale')\n",
    "\n",
    "y_pred_bin = apply_svm(X_train_bin, X_test_bin, y_train_bin, best_kernel, C=c, coef0=coefficient, degree=degree)\n",
    "acc_bin_test = accuracy_score(y_test_bin, y_pred_bin)\n",
    "\n",
    "print(\"Binary classification accuracy:\",acc_bin_test,\" for kernel:\",best_kernel,\"C:\",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__ ii)\n",
    "SVM classifier was trained with best kernel and best c value determined in binary classification for 15 class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 class classification accuracy: 1.0  for kernel: linear C: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Compute validation accuracy\n",
    "y_pred = apply_svm(X_train, X_test, y_train, best_kernel, c)\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "print(\"15 class classification accuracy:\",acc_test,\" for kernel:\",best_kernel,\"C:\",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__ iii)\n",
    "Both binary classification and 15-class classification resulted in an accuracy of 1.0, indicating excellent classification performance on the test data. \n",
    "\n",
    "The classification scores are also 1.0 for both classification tasks, showing excellent performance for all classes in both classification.\n",
    "\n",
    "This suggests that the chosen hyperparameters (kernel: linear, C: 0.1) can effectively separate classes in both classification tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: linear C: 0.1\n",
      "Binary classification accuracy = 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       127\n",
      "   macro avg       1.00      1.00      1.00       127\n",
      "weighted avg       1.00      1.00      1.00       127\n",
      "\n",
      "15 class classification accuracy = 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "         2.0       1.00      1.00      1.00        66\n",
      "         3.0       1.00      1.00      1.00        70\n",
      "         4.0       1.00      1.00      1.00        71\n",
      "         5.0       1.00      1.00      1.00        58\n",
      "         6.0       1.00      1.00      1.00        70\n",
      "         7.0       1.00      1.00      1.00        55\n",
      "         8.0       1.00      1.00      1.00        75\n",
      "         9.0       1.00      1.00      1.00        65\n",
      "        10.0       1.00      1.00      1.00        93\n",
      "        11.0       1.00      1.00      1.00        67\n",
      "        12.0       1.00      1.00      1.00        62\n",
      "        13.0       1.00      1.00      1.00        64\n",
      "        14.0       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report_bin=classification_report(y_test_bin,y_pred_bin)\n",
    "class_report=classification_report(y_test,y_pred)\n",
    "\n",
    "print(f'kernel: {best_kernel} C: {c}')\n",
    "print(f'Binary classification accuracy = {acc_bin_test}')\n",
    "print(class_report_bin)\n",
    "print(f'15 class classification accuracy = {acc_test}')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b)__ Grid search was used to tune the hyperparameters such as C, degree, gamma, coefficient(coef0).\n",
    "For hard margin SVM C value is 10e20. For soft margin SVM C value was tuned by using Grid search.\n",
    "For non-linear SVM, best kernel function was determined with Grid search in polynomial, sigmoid and rbf. After the best kernel function was determined, corresponding parameters such as gamma, coefficient and degree were determined with Grid Search.\n",
    "Because polynomial function was selected for bot non-linear situation, only degree was tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard-margin linear SVM \n",
    "\n",
    "Both binary classification and 15-class classification resulted in an accuracy of 1.0, indicating excellent classification performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard margin linear SVM C = 1e+21 kernel = linear\n",
      "Binary classification accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       127\n",
      "   macro avg       1.00      1.00      1.00       127\n",
      "weighted avg       1.00      1.00      1.00       127\n",
      "\n",
      "15 class classification accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "         2.0       1.00      1.00      1.00        66\n",
      "         3.0       1.00      1.00      1.00        70\n",
      "         4.0       1.00      1.00      1.00        71\n",
      "         5.0       1.00      1.00      1.00        58\n",
      "         6.0       1.00      1.00      1.00        70\n",
      "         7.0       1.00      1.00      1.00        55\n",
      "         8.0       1.00      1.00      1.00        75\n",
      "         9.0       1.00      1.00      1.00        65\n",
      "        10.0       1.00      1.00      1.00        93\n",
      "        11.0       1.00      1.00      1.00        67\n",
      "        12.0       1.00      1.00      1.00        62\n",
      "        13.0       1.00      1.00      1.00        64\n",
      "        14.0       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hard-margin linear SVM\n",
    "C_hard = 10e20\n",
    "y_pred_bin_hm_lin = apply_svm(X_train_bin, X_test_bin, y_train_bin, 'linear', C_hard)\n",
    "acc_bin_hm_lin = accuracy_score(y_test_bin, y_pred_bin_hm_lin)\n",
    "y_pred_hm_lin = apply_svm(X_train, X_test, y_train, 'linear', C_hard)\n",
    "acc_hm_lin = accuracy_score(y_test, y_pred_hm_lin)\n",
    "\n",
    "class_report_bin_hm_lin=classification_report(y_test_bin,y_pred_bin_hm_lin)\n",
    "class_report_hm_lin=classification_report(y_test,y_pred_hm_lin)\n",
    "\n",
    "print(f'Hard margin linear SVM C = {C_hard} kernel = linear')\n",
    "print(\"Binary classification accuracy :\",acc_bin_hm_lin)\n",
    "print(class_report_bin_hm_lin)\n",
    "print(\"15 class classification accuracy :\",acc_hm_lin)\n",
    "print(class_report_hm_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soft-margin linear SVM\n",
    "\n",
    "Both binary classification and 15-class classification resulted in an accuracy of 1.0, indicating excellent classification performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft margin linear SVM C = 0.1 kernel = linear\n",
      "Binary classification accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       127\n",
      "   macro avg       1.00      1.00      1.00       127\n",
      "weighted avg       1.00      1.00      1.00       127\n",
      "\n",
      "15 class classification accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "         2.0       1.00      1.00      1.00        66\n",
      "         3.0       1.00      1.00      1.00        70\n",
      "         4.0       1.00      1.00      1.00        71\n",
      "         5.0       1.00      1.00      1.00        58\n",
      "         6.0       1.00      1.00      1.00        70\n",
      "         7.0       1.00      1.00      1.00        55\n",
      "         8.0       1.00      1.00      1.00        75\n",
      "         9.0       1.00      1.00      1.00        65\n",
      "        10.0       1.00      1.00      1.00        93\n",
      "        11.0       1.00      1.00      1.00        67\n",
      "        12.0       1.00      1.00      1.00        62\n",
      "        13.0       1.00      1.00      1.00        64\n",
      "        14.0       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# soft-margin linear SVM\n",
    "# nonzero C value (e.g., 1, 10, or 100)\n",
    "C_grid = {'C': [0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# Perform a grid search with 5-fold cross-validation to find the best value of C\n",
    "svm = SVC(kernel='linear')\n",
    "grid_search = GridSearchCV(svm, C_grid, cv=5)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "C_sm_lin = grid_search.best_params_['C']\n",
    "\n",
    "y_pred_bin_sm_lin = apply_svm(X_train_bin, X_test_bin, y_train_bin, 'linear',C=C_sm_lin)\n",
    "acc_bin_sm_lin = accuracy_score(y_test_bin, y_pred_bin_sm_lin)\n",
    "y_pred_sm_lin = apply_svm(X_train, X_test, y_train, 'linear', C= C_sm_lin)\n",
    "acc_sm_lin = accuracy_score(y_test, y_pred_sm_lin)\n",
    "\n",
    "class_report_bin_sm_lin=classification_report(y_test_bin,y_pred_bin_sm_lin)\n",
    "class_report_sm_lin=classification_report(y_test,y_pred_sm_lin)\n",
    "\n",
    "print(f'Soft margin linear SVM C = {C_sm_lin} kernel = linear')\n",
    "print(\"Binary classification accuracy :\",acc_bin_sm_lin)\n",
    "print(class_report_bin_sm_lin)\n",
    "print(\"15 class classification accuracy :\",acc_sm_lin)\n",
    "print(class_report_sm_lin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard-margin non-linear SVM\n",
    "\n",
    "Both binary classification and 15-class classification resulted in an accuracy of 1.0, indicating excellent classification performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard margin non linear SVM C = 1e+21 kernel = poly\n",
      "Binary classification accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       127\n",
      "   macro avg       1.00      1.00      1.00       127\n",
      "weighted avg       1.00      1.00      1.00       127\n",
      "\n",
      "15 class classification accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "         2.0       1.00      1.00      1.00        66\n",
      "         3.0       1.00      1.00      1.00        70\n",
      "         4.0       1.00      1.00      1.00        71\n",
      "         5.0       1.00      1.00      1.00        58\n",
      "         6.0       1.00      1.00      1.00        70\n",
      "         7.0       1.00      1.00      1.00        55\n",
      "         8.0       1.00      1.00      1.00        75\n",
      "         9.0       1.00      1.00      1.00        65\n",
      "        10.0       1.00      1.00      1.00        93\n",
      "        11.0       1.00      1.00      1.00        67\n",
      "        12.0       1.00      1.00      1.00        62\n",
      "        13.0       1.00      1.00      1.00        64\n",
      "        14.0       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hard-margin non-linear SVM with various kernel functions\n",
    "kernel_grid = {'kernel': ['poly','rbf', 'sigmoid']}\n",
    "# Perform a grid search with 5-fold cross-validation to find the best kernel function\n",
    "svm = SVC(C=C_hard)\n",
    "grid_search = GridSearchCV(svm, kernel_grid, cv=5)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "kernel_hm_nonlin = grid_search.best_params_['kernel']\n",
    "\n",
    "svm = SVC(kernel=kernel_hm_nonlin, C=C_hard)\n",
    "\n",
    "if kernel_hm_nonlin=='poly':\n",
    "    poly_grid = {'degree':[2,3,4,5], 'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, poly_grid, cv=5)\n",
    "    \n",
    "elif kernel_hm_nonlin=='rbf':\n",
    "    rbf_grid = {'gamma':[1,0.1,0.01,0.001]}\n",
    "    grid_search = GridSearchCV(svm, rbf_grid, cv=5)\n",
    "    \n",
    "elif kernel_hm_nonlin=='sigmoid':\n",
    "    sigmoid_grid = {'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, sigmoid_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "degree = grid_search.best_params_.get('degree',3)\n",
    "coefficient = grid_search.best_params_.get('coef0',0.0)\n",
    "gamma = grid_search.best_params_.get('gamma','scale')\n",
    "\n",
    "y_pred_bin_hm_nonlin = apply_svm(X_train_bin, X_test_bin, y_train_bin, kernel_hm_nonlin, C=C_hard,coef0=coefficient,degree=degree)\n",
    "acc_bin_hm_nonlin = accuracy_score(y_test_bin, y_pred_bin_hm_nonlin)\n",
    "y_pred_hm_nonlin = apply_svm(X_train, X_test, y_train, kernel_hm_nonlin, C=C_hard)\n",
    "acc_hm_nonlin = accuracy_score(y_test, y_pred_hm_nonlin)\n",
    "\n",
    "class_report_bin_hm_nonlin=classification_report(y_test_bin,y_pred_bin_hm_nonlin)\n",
    "class_report_hm_nonlin=classification_report(y_test,y_pred_hm_nonlin)\n",
    "\n",
    "\n",
    "print(f'Hard margin non linear SVM C = {C_hard} kernel = {kernel_hm_nonlin}')\n",
    "print(\"Binary classification accuracy :\",acc_bin_hm_nonlin)\n",
    "print(class_report_bin_hm_nonlin)\n",
    "print(\"15 class classification accuracy :\",acc_hm_nonlin)\n",
    "print(class_report_hm_nonlin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soft-margin non-linear SVM\n",
    "\n",
    "Both binary classification and 15-class classification resulted in an accuracy of 1.0, indicating excellent classification performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft margin non linear SVM C = 0.1 kernel = poly\n",
      "Binary classification accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       127\n",
      "   macro avg       1.00      1.00      1.00       127\n",
      "weighted avg       1.00      1.00      1.00       127\n",
      "\n",
      "15 class classification accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "         2.0       1.00      1.00      1.00        66\n",
      "         3.0       1.00      1.00      1.00        70\n",
      "         4.0       1.00      1.00      1.00        71\n",
      "         5.0       1.00      1.00      1.00        58\n",
      "         6.0       1.00      1.00      1.00        70\n",
      "         7.0       1.00      1.00      1.00        55\n",
      "         8.0       1.00      1.00      1.00        75\n",
      "         9.0       1.00      1.00      1.00        65\n",
      "        10.0       1.00      1.00      1.00        93\n",
      "        11.0       1.00      1.00      1.00        67\n",
      "        12.0       1.00      1.00      1.00        62\n",
      "        13.0       1.00      1.00      1.00        64\n",
      "        14.0       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# soft-margin non-linear SVM with various kernel functions\n",
    "svm = SVC()\n",
    "grid_search = GridSearchCV(svm, kernel_grid, cv=3)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "kernel_sm_nonlin = grid_search.best_params_['kernel']\n",
    "\n",
    "svm = SVC(kernel = kernel_sm_nonlin)\n",
    "grid_search = GridSearchCV(svm, C_grid, cv=5)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "C_sm_nonlin = grid_search.best_params_['C']\n",
    "\n",
    "if kernel_hm_nonlin=='poly':\n",
    "    poly_grid = {'degree':[2,3,4,5], 'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, poly_grid, cv=4)\n",
    "    \n",
    "elif kernel_hm_nonlin=='rbf':\n",
    "    rbf_grid = {'gamma':[1,0.1,0.01,0.001]}\n",
    "    grid_search = GridSearchCV(svm, rbf_grid, cv=4)\n",
    "    \n",
    "elif kernel_hm_nonlin=='sigmoid':\n",
    "    sigmoid_grid = {'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, sigmoid_grid, cv=4)\n",
    "\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "degree = grid_search.best_params_.get('degree',3)\n",
    "coefficient = grid_search.best_params_.get('coef0',0.0)\n",
    "gamma = grid_search.best_params_.get('gamma','scale')\n",
    "\n",
    "y_pred_bin_sm_nonlin = apply_svm(X_train_bin, X_test_bin, y_train_bin, kernel_sm_nonlin, C=C_sm_nonlin,coef0=coefficient,degree=degree)\n",
    "acc_bin_sm_nonlin = accuracy_score(y_test_bin, y_pred_bin_sm_nonlin)\n",
    "y_pred_sm_nonlin = apply_svm(X_train, X_test, y_train, kernel_sm_nonlin, C=C_sm_nonlin)\n",
    "acc_sm_nonlin = accuracy_score(y_test, y_pred_sm_nonlin)\n",
    "\n",
    "class_report_bin_sm_nonlin=classification_report(y_test_bin,y_pred_bin_sm_nonlin)\n",
    "class_report_sm_nonlin=classification_report(y_test,y_pred_sm_nonlin)\n",
    "\n",
    "print(f'Soft margin non linear SVM C = {C_sm_nonlin} kernel = {kernel_sm_nonlin}')\n",
    "print(\"Binary classification accuracy :\",acc_bin_sm_nonlin)\n",
    "print(class_report_bin_sm_nonlin)\n",
    "print(\"15 class classification accuracy :\",acc_sm_nonlin)\n",
    "print(class_report_sm_nonlin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c)__ PCA with 10 principle components is applied as the feature extraction method. SVM classifier is trained on data on which PCA applied. For the binary case, we got the perfect result as before. However, for the 15-class classification, we have seen a little decrease in accuracy.The reason that it is slightly worse than the previous result (1.0) might be the fact that we did not extract enough features for 15-class classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_svm_with_pca(X_train,X_test, y_train, kernel='rfb', C=1.0, gamma='scale'):\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled_train = scaler.fit_transform(X_train)\n",
    "    X_scaled_test = scaler.transform(X_test)\n",
    "\n",
    "    # Apply PCA to extract principal components\n",
    "    pca = PCA(n_components=10)     # n_components can be changed to extract more or fewer principal components as needed.\n",
    "    X_train_pca = pca.fit_transform(X_scaled_train)\n",
    "    X_test_pca = pca.transform(X_scaled_test)\n",
    "    \n",
    "    clf = SVC(kernel=kernel, C=C, gamma=gamma)\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Predict labels for validation set\n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification accuracy before pca: 1.0\n",
      "Binary classification accuracy after pca: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       127\n",
      "   macro avg       1.00      1.00      1.00       127\n",
      "weighted avg       1.00      1.00      1.00       127\n",
      "\n",
      "15 class classification accuracy before pca: 1.0\n",
      "15 class classification accuracy after pca: 0.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.89      0.88        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "         2.0       0.94      0.89      0.91        66\n",
      "         3.0       0.94      0.97      0.96        70\n",
      "         4.0       0.97      0.94      0.96        71\n",
      "         5.0       0.85      0.88      0.86        58\n",
      "         6.0       0.94      0.97      0.96        70\n",
      "         7.0       0.94      0.87      0.91        55\n",
      "         8.0       0.99      0.96      0.97        75\n",
      "         9.0       0.98      0.95      0.97        65\n",
      "        10.0       0.97      0.90      0.93        93\n",
      "        11.0       0.90      0.94      0.92        67\n",
      "        12.0       0.89      1.00      0.94        62\n",
      "        13.0       0.91      0.92      0.91        64\n",
      "        14.0       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.94      0.94      0.94      1000\n",
      "weighted avg       0.94      0.94      0.94      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute validation accuracy for binary classification with pca\n",
    "y_pred_bin_pca = apply_svm_with_pca(X_train_bin, X_test_bin, y_train_bin, best_kernel, c)\n",
    "acc_bin_test_pca = accuracy_score(y_test_bin, y_pred_bin_pca)\n",
    "\n",
    "# Compute validation accuracy for 15 class classification with pca\n",
    "y_pred_pca = apply_svm_with_pca(X_train, X_test, y_train, best_kernel, c)\n",
    "acc_test_pca = accuracy_score(y_test, y_pred_pca)\n",
    "\n",
    "class_report_bin_pca = classification_report(y_test_bin,y_pred_bin_pca)\n",
    "class_report_pca=classification_report(y_test,y_pred_pca)\n",
    "\n",
    "print(\"Binary classification accuracy before pca:\", acc_bin_test)\n",
    "print(\"Binary classification accuracy after pca:\", acc_bin_test_pca)\n",
    "print(class_report_bin_pca)\n",
    "print(\"15 class classification accuracy before pca:\",acc_test)\n",
    "print(\"15 class classification accuracy after pca:\",acc_test_pca)\n",
    "print(class_report_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
