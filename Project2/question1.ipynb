{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skimage.feature import hog\n",
    "\n",
    "y_train = np.load(\"orientations_train.npy\")\n",
    "y_test = np.load(\"orientations_test.npy\")\n",
    "\n",
    "test_size = 1000\n",
    "train_size = 10000\n",
    "image_length = 4096  #1764\n",
    "image_dim = 64\n",
    "\n",
    "def vectorize_images(filename, data_size):\n",
    "    X = np.empty(shape=(data_size, image_length))\n",
    "   \n",
    "    for i in range(data_size):     \n",
    "        img = cv.imread(\"{filename}/{i}.jpg\".format(filename = filename, i = i), cv.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        \"\"\"img_reshaped = img.reshape((image_dim, image_dim))\n",
    "\n",
    "        # Perform HOG feature extraction for the image\n",
    "        hog_img = hog(img_reshaped, orientations=9, pixels_per_cell=(8, 8),\n",
    "                      cells_per_block=(2, 2), visualize=False)\n",
    "                      \n",
    "        # orientations : Number of gradient orientations\n",
    "        # pixels_per_cell : Size of each cell\n",
    "        # cells_per_block : Number of cells in each block\n",
    "        \n",
    "        X[i] = hog_img.flatten()\"\"\"\n",
    "        \n",
    "        X[i] = img.flatten()\n",
    "        \n",
    "    return X\n",
    "\n",
    "X_train = vectorize_images(\"3dshapes_train\" ,train_size)\n",
    "X_test = vectorize_images(\"3dshapes_test\" ,test_size)\n",
    "\n",
    "# Convert labels to integers from 0 to 14\n",
    "train_orients_set = list(set(y_train))\n",
    "for i in range(len(train_orients_set)):\n",
    "    y_train[y_train == train_orients_set[i]] = i\n",
    "        \n",
    "test_orients_set = list(set(y_test))\n",
    "for i in range(len(test_orients_set)):\n",
    "    y_test[y_test == test_orients_set[i]] = i\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_svm(X_train, X_test, y_train, kernel, C=1.0, gamma='scale',coef0=0.0, degree=3):\n",
    "    # Train SVM classifier\n",
    "    # C: regularization parameter of the SVM\n",
    "         # A small value of C will result in a wider margin hyperplane and a larger number of support vectors. \n",
    "         # A large value of C will result in a a narrow margin hyperplane and smaller number of support vectors.\n",
    "    clf = SVC(kernel=kernel, C=C, gamma=gamma)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    # Predict labels for validation set\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    return y_pred_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__ i)\n",
    "\n",
    "Grid Search was used to determine best kernel function and best value of regularization parameter of SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification accuracy: 1.0  for kernel: linear C: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Select two orientations for binary classification\n",
    "# Create binary label vectors\n",
    "y_train_bin = np.empty(train_size)\n",
    "y_test_bin = np.empty(test_size)\n",
    "\n",
    "y_train_bin = np.delete(y_train, np.argwhere( (y_train != 0) & (y_train != 1) ))\n",
    "X_train_bin = X_train[(y_train == 0) | (y_train == 1)]\n",
    "\n",
    "y_test_bin = np.delete(y_test, np.argwhere( (y_test != 0) & (y_test != 1) ))\n",
    "X_test_bin = X_test[(y_test == 0) | (y_test == 1)]\n",
    "\n",
    "# Compute accuracy with best kernal and c(regularization parameter)\n",
    "C_grid = {'C': [0.1, 1, 10, 100, 1000]}\n",
    "kernel_grid = {'kernel':['linear','poly','rbf','sigmoid']}\n",
    "svm = SVC()\n",
    "grid_search = GridSearchCV(svm, kernel_grid, cv=4)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "best_kernel = grid_search.best_params_['kernel']\n",
    "\n",
    "svm = SVC(kernel = best_kernel)\n",
    "grid_search = GridSearchCV(svm, C_grid, cv=5)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "c = grid_search.best_params_['C']\n",
    "\n",
    "if best_kernel=='poly':\n",
    "    poly_grid = {'degree':[2,3,4,5], 'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, poly_grid, cv=4)\n",
    "    grid_search.fit(X_train_bin, y_train_bin)\n",
    "    \n",
    "elif best_kernel=='rbf':\n",
    "    rbf_grid = {'gamma':[1,0.1,0.01,0.001]}\n",
    "    grid_search = GridSearchCV(svm, rbf_grid, cv=4)\n",
    "    grid_search.fit(X_train_bin, y_train_bin)\n",
    "    \n",
    "elif best_kernel=='sigmoid':\n",
    "    sigmoid_grid = {'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, sigmoid_grid, cv=4)\n",
    "    grid_search.fit(X_train_bin, y_train_bin)\n",
    "    \n",
    "degree = grid_search.best_params_.get('degree',3)\n",
    "coefficient = grid_search.best_params_.get('coef0',0.0)\n",
    "gamma = grid_search.best_params_.get('gamma','scale')\n",
    "\n",
    "y_pred_bin = apply_svm(X_train_bin, X_test_bin, y_train_bin, best_kernel, C=c, coef0=coefficient, degree=degree)\n",
    "acc_bin_test = accuracy_score(y_test_bin, y_pred_bin)\n",
    "\n",
    "print(\"Binary classification accuracy:\",acc_bin_test,\" for kernel:\",best_kernel,\"C:\",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__ ii)\n",
    "SVM classifier was trained with best kernel and best c value determined in binary classification for 15 class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 class classification accuracy: 1.0  for kernel: linear C: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Compute validation accuracy\n",
    "y_pred = apply_svm(X_train, X_test, y_train, best_kernel, c)\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "print(\"15 class classification accuracy:\",acc_test,\" for kernel:\",best_kernel,\"C:\",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__ iii)\n",
    "Both binary classification and 15-class classification resulted in an accuracy of 1.0, indicating excellent classification performance on the test data. \n",
    "\n",
    "The classification scores are also 1.0 for both classification tasks, showing excellent performance for all classes in both classification.\n",
    "\n",
    "This suggests that the chosen hyperparameters (kernel: linear, C: 0.1) can effectively separate classes in both classification tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: linear C: 0.1\n",
      "Binary classification accuracy = 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       127\n",
      "   macro avg       1.00      1.00      1.00       127\n",
      "weighted avg       1.00      1.00      1.00       127\n",
      "\n",
      "15 class classification accuracy = 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "         2.0       1.00      1.00      1.00        66\n",
      "         3.0       1.00      1.00      1.00        70\n",
      "         4.0       1.00      1.00      1.00        71\n",
      "         5.0       1.00      1.00      1.00        58\n",
      "         6.0       1.00      1.00      1.00        70\n",
      "         7.0       1.00      1.00      1.00        55\n",
      "         8.0       1.00      1.00      1.00        75\n",
      "         9.0       1.00      1.00      1.00        65\n",
      "        10.0       1.00      1.00      1.00        93\n",
      "        11.0       1.00      1.00      1.00        67\n",
      "        12.0       1.00      1.00      1.00        62\n",
      "        13.0       1.00      1.00      1.00        64\n",
      "        14.0       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_report_bin=classification_report(y_test_bin,y_pred_bin)\n",
    "class_report=classification_report(y_test,y_pred)\n",
    "\n",
    "print(f'kernel: {best_kernel} C: {c}')\n",
    "print(f'Binary classification accuracy = {acc_bin_test}')\n",
    "print(class_report_bin)\n",
    "print(f'15 class classification accuracy = {acc_test}')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b)__ Grid search was used to tune the hyperparameters such as C, degree, gamma, coefficient(coef0).\n",
    "For hard margin SVM C value is 10e21. For soft margin SVM C value was tuned by using Grid search.\n",
    "For non-linear SVM, best kernel function was determined with Grid search in polynomial, sigmoid and rbf. After the best kernel function was determined, corresponding parameters such as gamma, coefficient and degree were determined with Grid Search.\n",
    "Because polynomial function was selected for bot non-linear situation, only degree was tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard-margin linear SVM\n",
    "\n",
    "Both binary classification and 15-class classification resulted in an accuracy of 1.0, indicating excellent classification performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard margin linear SVM C = 1e+21 kernel = linear\n",
      "Binary classification accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       127\n",
      "   macro avg       1.00      1.00      1.00       127\n",
      "weighted avg       1.00      1.00      1.00       127\n",
      "\n",
      "15 class classification accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "         2.0       1.00      1.00      1.00        66\n",
      "         3.0       1.00      1.00      1.00        70\n",
      "         4.0       1.00      1.00      1.00        71\n",
      "         5.0       1.00      1.00      1.00        58\n",
      "         6.0       1.00      1.00      1.00        70\n",
      "         7.0       1.00      1.00      1.00        55\n",
      "         8.0       1.00      1.00      1.00        75\n",
      "         9.0       1.00      1.00      1.00        65\n",
      "        10.0       1.00      1.00      1.00        93\n",
      "        11.0       1.00      1.00      1.00        67\n",
      "        12.0       1.00      1.00      1.00        62\n",
      "        13.0       1.00      1.00      1.00        64\n",
      "        14.0       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hard-margin linear SVM\n",
    "C_hard = 10e20\n",
    "y_pred_bin_hm_lin = apply_svm(X_train_bin, X_test_bin, y_train_bin, 'linear', C_hard)\n",
    "acc_bin_hm_lin = accuracy_score(y_test_bin, y_pred_bin_hm_lin)\n",
    "y_pred_hm_lin = apply_svm(X_train, X_test, y_train, 'linear', C_hard)\n",
    "acc_hm_lin = accuracy_score(y_test, y_pred_hm_lin)\n",
    "\n",
    "class_report_bin_hm_lin=classification_report(y_test_bin,y_pred_bin_hm_lin)\n",
    "class_report_hm_lin=classification_report(y_test,y_pred_hm_lin)\n",
    "\n",
    "print(f'Hard margin linear SVM C = {C_hard} kernel = linear')\n",
    "print(\"Binary classification accuracy :\",acc_bin_hm_lin)\n",
    "print(class_report_bin_hm_lin)\n",
    "print(\"15 class classification accuracy :\",acc_hm_lin)\n",
    "print(class_report_hm_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soft-margin linear SVM\n",
    "\n",
    "Both binary classification and 15-class classification resulted in an accuracy of 1.0, indicating excellent classification performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft margin linear SVM C = 0.1 kernel = linear\n",
      "Binary classification accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       127\n",
      "   macro avg       1.00      1.00      1.00       127\n",
      "weighted avg       1.00      1.00      1.00       127\n",
      "\n",
      "15 class classification accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "         2.0       1.00      1.00      1.00        66\n",
      "         3.0       1.00      1.00      1.00        70\n",
      "         4.0       1.00      1.00      1.00        71\n",
      "         5.0       1.00      1.00      1.00        58\n",
      "         6.0       1.00      1.00      1.00        70\n",
      "         7.0       1.00      1.00      1.00        55\n",
      "         8.0       1.00      1.00      1.00        75\n",
      "         9.0       1.00      1.00      1.00        65\n",
      "        10.0       1.00      1.00      1.00        93\n",
      "        11.0       1.00      1.00      1.00        67\n",
      "        12.0       1.00      1.00      1.00        62\n",
      "        13.0       1.00      1.00      1.00        64\n",
      "        14.0       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# soft-margin linear SVM\n",
    "# nonzero C value (e.g., 1, 10, or 100)\n",
    "C_grid = {'C': [0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# Perform a grid search with 5-fold cross-validation to find the best value of C\n",
    "svm = SVC(kernel='linear')\n",
    "grid_search = GridSearchCV(svm, C_grid, cv=5)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "C_sm_lin = grid_search.best_params_['C']\n",
    "\n",
    "y_pred_bin_sm_lin = apply_svm(X_train_bin, X_test_bin, y_train_bin, 'linear',C=C_sm_lin)\n",
    "acc_bin_sm_lin = accuracy_score(y_test_bin, y_pred_bin_sm_lin)\n",
    "y_pred_sm_lin = apply_svm(X_train, X_test, y_train, 'linear', C= C_sm_lin)\n",
    "acc_sm_lin = accuracy_score(y_test, y_pred_sm_lin)\n",
    "\n",
    "class_report_bin_sm_lin=classification_report(y_test_bin,y_pred_bin_sm_lin)\n",
    "class_report_sm_lin=classification_report(y_test,y_pred_sm_lin)\n",
    "\n",
    "print(f'Soft margin linear SVM C = {C_sm_lin} kernel = linear')\n",
    "print(\"Binary classification accuracy :\",acc_bin_sm_lin)\n",
    "print(class_report_bin_sm_lin)\n",
    "print(\"15 class classification accuracy :\",acc_sm_lin)\n",
    "print(class_report_sm_lin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard-margin non-linear SVM\n",
    "\n",
    "Both binary classification and 15-class classification resulted in an accuracy of 1.0, indicating excellent classification performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard margin non linear SVM C = 1e+21 kernel = poly\n",
      "Binary classification accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       127\n",
      "   macro avg       1.00      1.00      1.00       127\n",
      "weighted avg       1.00      1.00      1.00       127\n",
      "\n",
      "15 class classification accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "         2.0       1.00      1.00      1.00        66\n",
      "         3.0       1.00      1.00      1.00        70\n",
      "         4.0       1.00      1.00      1.00        71\n",
      "         5.0       1.00      1.00      1.00        58\n",
      "         6.0       1.00      1.00      1.00        70\n",
      "         7.0       1.00      1.00      1.00        55\n",
      "         8.0       1.00      1.00      1.00        75\n",
      "         9.0       1.00      1.00      1.00        65\n",
      "        10.0       1.00      1.00      1.00        93\n",
      "        11.0       1.00      1.00      1.00        67\n",
      "        12.0       1.00      1.00      1.00        62\n",
      "        13.0       1.00      1.00      1.00        64\n",
      "        14.0       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hard-margin non-linear SVM with various kernel functions\n",
    "kernel_grid = {'kernel': ['poly','rbf', 'sigmoid']}\n",
    "# Perform a grid search with 3-fold cross-validation to find the best kernel function\n",
    "svm = SVC(C=C_hard)\n",
    "grid_search = GridSearchCV(svm, kernel_grid, cv=5)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "kernel_hm_nonlin = grid_search.best_params_['kernel']\n",
    "\n",
    "svm = SVC(kernel=kernel_hm_nonlin, C=C_hard)\n",
    "\n",
    "if kernel_hm_nonlin=='poly':\n",
    "    poly_grid = {'degree':[2,3,4,5], 'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, poly_grid, cv=5)\n",
    "    \n",
    "elif kernel_hm_nonlin=='rbf':\n",
    "    rbf_grid = {'gamma':[1,0.1,0.01,0.001]}\n",
    "    grid_search = GridSearchCV(svm, rbf_grid, cv=5)\n",
    "    \n",
    "elif kernel_hm_nonlin=='sigmoid':\n",
    "    sigmoid_grid = {'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, sigmoid_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "degree = grid_search.best_params_.get('degree',3)\n",
    "coefficient = grid_search.best_params_.get('coef0',0.0)\n",
    "gamma = grid_search.best_params_.get('gamma','scale')\n",
    "\n",
    "y_pred_bin_hm_nonlin = apply_svm(X_train_bin, X_test_bin, y_train_bin, kernel_hm_nonlin, C=C_hard,coef0=coefficient,degree=degree)\n",
    "acc_bin_hm_nonlin = accuracy_score(y_test_bin, y_pred_bin_hm_nonlin)\n",
    "y_pred_hm_nonlin = apply_svm(X_train, X_test, y_train, kernel_hm_nonlin, C=C_hard)\n",
    "acc_hm_nonlin = accuracy_score(y_test, y_pred_hm_nonlin)\n",
    "\n",
    "class_report_bin_hm_nonlin=classification_report(y_test_bin,y_pred_bin_hm_nonlin)\n",
    "class_report_hm_nonlin=classification_report(y_test,y_pred_hm_nonlin)\n",
    "\n",
    "\n",
    "print(f'Hard margin non linear SVM C = {C_hard} kernel = {kernel_hm_nonlin}')\n",
    "print(\"Binary classification accuracy :\",acc_bin_hm_nonlin)\n",
    "print(class_report_bin_hm_nonlin)\n",
    "print(\"15 class classification accuracy :\",acc_hm_nonlin)\n",
    "print(class_report_hm_nonlin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soft-margin non-linear SVM\n",
    "\n",
    "Both binary classification and 15-class classification resulted in an accuracy of 1.0, indicating excellent classification performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft margin non linear SVM C = 0.1 kernel = poly\n",
      "Binary classification accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       127\n",
      "   macro avg       1.00      1.00      1.00       127\n",
      "weighted avg       1.00      1.00      1.00       127\n",
      "\n",
      "15 class classification accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "         2.0       1.00      1.00      1.00        66\n",
      "         3.0       1.00      1.00      1.00        70\n",
      "         4.0       1.00      1.00      1.00        71\n",
      "         5.0       1.00      1.00      1.00        58\n",
      "         6.0       1.00      1.00      1.00        70\n",
      "         7.0       1.00      1.00      1.00        55\n",
      "         8.0       1.00      1.00      1.00        75\n",
      "         9.0       1.00      1.00      1.00        65\n",
      "        10.0       1.00      1.00      1.00        93\n",
      "        11.0       1.00      1.00      1.00        67\n",
      "        12.0       1.00      1.00      1.00        62\n",
      "        13.0       1.00      1.00      1.00        64\n",
      "        14.0       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# soft-margin non-linear SVM with various kernel functions\n",
    "svm = SVC()\n",
    "grid_search = GridSearchCV(svm, kernel_grid, cv=3)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "kernel_sm_nonlin = grid_search.best_params_['kernel']\n",
    "\n",
    "svm = SVC(kernel = kernel_sm_nonlin)\n",
    "grid_search = GridSearchCV(svm, C_grid, cv=5)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "C_sm_nonlin = grid_search.best_params_['C']\n",
    "\n",
    "if kernel_hm_nonlin=='poly':\n",
    "    poly_grid = {'degree':[2,3,4,5], 'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, poly_grid, cv=4)\n",
    "    \n",
    "elif kernel_hm_nonlin=='rbf':\n",
    "    rbf_grid = {'gamma':[1,0.1,0.01,0.001]}\n",
    "    grid_search = GridSearchCV(svm, rbf_grid, cv=4)\n",
    "    \n",
    "elif kernel_hm_nonlin=='sigmoid':\n",
    "    sigmoid_grid = {'coef0':[0.0,0.1,0.2,0.3]}\n",
    "    grid_search = GridSearchCV(svm, sigmoid_grid, cv=4)\n",
    "\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "degree = grid_search.best_params_.get('degree',3)\n",
    "coefficient = grid_search.best_params_.get('coef0',0.0)\n",
    "gamma = grid_search.best_params_.get('gamma','scale')\n",
    "\n",
    "y_pred_bin_sm_nonlin = apply_svm(X_train_bin, X_test_bin, y_train_bin, kernel_sm_nonlin, C=C_sm_nonlin,coef0=coefficient,degree=degree)\n",
    "acc_bin_sm_nonlin = accuracy_score(y_test_bin, y_pred_bin_sm_nonlin)\n",
    "y_pred_sm_nonlin = apply_svm(X_train, X_test, y_train, kernel_sm_nonlin, C=C_sm_nonlin)\n",
    "acc_sm_nonlin = accuracy_score(y_test, y_pred_sm_nonlin)\n",
    "\n",
    "class_report_bin_sm_nonlin=classification_report(y_test_bin,y_pred_bin_sm_nonlin)\n",
    "class_report_sm_nonlin=classification_report(y_test,y_pred_sm_nonlin)\n",
    "\n",
    "print(f'Soft margin non linear SVM C = {C_sm_nonlin} kernel = {kernel_sm_nonlin}')\n",
    "print(\"Binary classification accuracy :\",acc_bin_sm_nonlin)\n",
    "print(class_report_bin_sm_nonlin)\n",
    "print(\"15 class classification accuracy :\",acc_sm_nonlin)\n",
    "print(class_report_sm_nonlin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_svm_with_pca(X_train,X_test, y_train, kernel='rfb', C=1.0, gamma='scale'):\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled_train = scaler.fit_transform(X_train)\n",
    "    X_scaled_test = scaler.transform(X_test)\n",
    "\n",
    "    # Apply PCA to extract principal components\n",
    "    pca = PCA(n_components=10)     # n_components can be changed to extract more or fewer principal components as needed.\n",
    "    X_train_pca = pca.fit_transform(X_scaled_train)\n",
    "    X_test_pca = pca.transform(X_scaled_test)\n",
    "    \n",
    "    clf = SVC(kernel=kernel, C=C, gamma=gamma)\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Predict labels for validation set\n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification accuracy before pca: 1.0\n",
      "Binary classification accuracy after pca: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        64\n",
      "         1.0       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       127\n",
      "   macro avg       1.00      1.00      1.00       127\n",
      "weighted avg       1.00      1.00      1.00       127\n",
      "\n",
      "15 class classification accuracy before pca: 1.0\n",
      "15 class classification accuracy after pca: 0.91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.89      0.84        64\n",
      "         1.0       0.80      0.87      0.83        63\n",
      "         2.0       0.90      0.92      0.91        66\n",
      "         3.0       0.88      0.76      0.82        70\n",
      "         4.0       1.00      1.00      1.00        71\n",
      "         5.0       0.86      0.88      0.87        58\n",
      "         6.0       1.00      1.00      1.00        70\n",
      "         7.0       0.90      0.95      0.92        55\n",
      "         8.0       0.94      0.96      0.95        75\n",
      "         9.0       1.00      1.00      1.00        65\n",
      "        10.0       0.94      0.90      0.92        93\n",
      "        11.0       0.97      0.93      0.95        67\n",
      "        12.0       0.88      0.90      0.89        62\n",
      "        13.0       0.91      0.81      0.86        64\n",
      "        14.0       0.86      0.86      0.86        57\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute validation accuracy for binary classification with pca\n",
    "y_pred_bin_pca = apply_svm_with_pca(X_train_bin, X_test_bin, y_train_bin, best_kernel, c)\n",
    "acc_bin_test_pca = accuracy_score(y_test_bin, y_pred_bin_pca)\n",
    "\n",
    "# Compute validation accuracy for 15 class classification with pca\n",
    "y_pred_pca = apply_svm_with_pca(X_train, X_test, y_train, best_kernel, c)\n",
    "acc_test_pca = accuracy_score(y_test, y_pred_pca)\n",
    "\n",
    "class_report_bin_pca = classification_report(y_test_bin,y_pred_bin_pca)\n",
    "class_report_pca=classification_report(y_test,y_pred_pca)\n",
    "\n",
    "print(\"Binary classification accuracy before pca:\", acc_bin_test)\n",
    "print(\"Binary classification accuracy after pca:\", acc_bin_test_pca)\n",
    "print(class_report_bin_pca)\n",
    "print(\"15 class classification accuracy before pca:\",acc_test)\n",
    "print(\"15 class classification accuracy after pca:\",acc_test_pca)\n",
    "print(class_report_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yorum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
