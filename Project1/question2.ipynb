{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34da147f",
   "metadata": {},
   "source": [
    "__(a)__ Below you can find the function to convert the images into grayscaled and flattened vectors with the help of OpenCV library. Later we will use this function to convert the images in the _3dshapes_train_ and _3dshapes_test_. We also keep the 2d versions as well since we will use them to extract features later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d63ec8d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import math\n",
    "\n",
    "y_train = np.load(\"orientations_train.npy\")\n",
    "\n",
    "train_size = 10000\n",
    "image_length = 4096\n",
    "image_dim = 64\n",
    "\n",
    "def vectorize_images(filename, data_size):\n",
    "    # X for training and X_2d for feature extraction\n",
    "    X = np.empty(shape=(data_size, image_length))\n",
    "    X_2d = np.empty(shape=(data_size, image_dim, image_dim), dtype='uint8')\n",
    "\n",
    "    for i in range(data_size):        \n",
    "        img = cv.imread(\"{filename}/{i}.jpg\".format(filename = filename, i = i), cv.IMREAD_GRAYSCALE)\n",
    "        X[i] = img.flatten()\n",
    "        X_2d[i] = img\n",
    "        \n",
    "    return X, X_2d\n",
    "\n",
    "X_train, X_train_2d = vectorize_images(\"3dshapes_train\" ,train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb56c7",
   "metadata": {},
   "source": [
    "__(b)__ In order to find the optimal weight vector coefficients, we set the gradient of the least square error function to 0. The closed-form solution we obtain is as follows: <br>\n",
    "\n",
    "$ \\mathbf{w}^* = {({X}^\\intercal X)}^{-1}{X}^\\intercal \\mathbf{t} $ <br>\n",
    "\n",
    "Below we implemented the function to calculate the optimal weights and used it to train the model. <br> <br>\n",
    "To test our model we first generated our predictions using the formula: $ \\hat{y} = Xw = X{({X}^\\intercal X)}^{-1}{X}^\\intercal \\mathbf{t} $ and then compared it with the actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "659bfc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the optimal parameters by minimizing the least squares error function\n",
    "def linear_regression(X, y):\n",
    "    return np.linalg.pinv(X.T @ X) @ X.T @ y\n",
    "\n",
    "w = linear_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f7bb3b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error is: 1.511688025740367e-06\n"
     ]
    }
   ],
   "source": [
    "y_test = np.load(\"orientations_test.npy\")\n",
    "\n",
    "test_size = 1000\n",
    "\n",
    "X_test, X_test_2d = vectorize_images(\"3dshapes_test\" ,test_size)\n",
    "y_prediction = X_test @ w\n",
    "\n",
    "RMSE = math.sqrt(np.square(np.subtract(y_test, y_prediction)).mean()) \n",
    "print(f\"Root Mean Square Error is: {RMSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6833c8b3",
   "metadata": {},
   "source": [
    "__(c)__ Below you can find SIFT (Scale-invariant feature transform) algorithm implementation of ours with the help of OpenCV documents. It basically finds keypoints and descriptors for each of the images. We trained our model with stacking these descriptors and their corresponding labels. <br>\n",
    "We chose SIFT as the feature extraction algorithm because as a result of our research we found that it is especially good at extracting features related to edges, corners, blobs, scale-invariant features and rotation-invariant features. Thus, we thought that it would make sense to use this algorithm to extract orientation related features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1201a14d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# RESOURCES: https://docs.opencv.org/4.x/da/df5/tutorial_py_sift_intro.html\n",
    "\n",
    "def extract_features(X_2d, y, data_size):\n",
    "    keypoints = np.empty(data_size, dtype=object)\n",
    "    number_of_keypoints = 0\n",
    "\n",
    "    # Initiate SIFT detector\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "\n",
    "    for i in range(data_size):\n",
    "        # find the keypoints\n",
    "        kp = sift.detect(X_2d[i], None)\n",
    "        keypoints[i] = kp\n",
    "        number_of_keypoints += len(kp)\n",
    "\n",
    "    X_sift = np.empty(shape = (number_of_keypoints, 128))\n",
    "    y_sift = np.empty(number_of_keypoints)\n",
    "\n",
    "    idx = 0\n",
    "    for i in range(data_size):\n",
    "        # find the descriptors\n",
    "        kp, desc = sift.compute(X_2d[i], keypoints[i])\n",
    "\n",
    "        if len(kp) != 0:\n",
    "            for d in desc:\n",
    "                X_sift[idx] = d\n",
    "                y_sift[idx] = y[i]\n",
    "                idx += 1\n",
    "    \n",
    "    return X_sift, y_sift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ae9a133f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error with the extracted features is: 17.759797638538384\n"
     ]
    }
   ],
   "source": [
    "# extracting features for training\n",
    "X_train_sift, y_train_sift = extract_features(X_train_2d, y_train, train_size)\n",
    "\n",
    "# training the model with the extracted features\n",
    "w_sift = linear_regression(X_train_sift, y_train_sift)\n",
    "\n",
    "# extracting features from the test data \n",
    "X_test_sift, y_test_sift = extract_features(X_test_2d, y_test, test_size)\n",
    "\n",
    "# making predictions using the w coming from the extracted data set\n",
    "y_prediction_sift = X_test_sift @ w_sift\n",
    "\n",
    "# calculating the RMSE\n",
    "RMSE_sift = math.sqrt(np.square(np.subtract(y_test_sift, y_prediction_sift)).mean()) \n",
    "print(f\"Root Mean Square Error with the extracted features is: {RMSE_sift}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf784fe",
   "metadata": {},
   "source": [
    "__(c)__ As it clearly can be seen, current result is much worse than the previous result. The main reason for this could be that we lose too much information in the feature extraction process, we don't extract the right features, or we do something wrong during implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d895b519",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
